"""
GraphQL type for Run

Auto-generated by running 'make codegen'. Do not edit.
Make changes to the template codegen/templates/graphql_api/types/class_name.py.j2 instead.
"""

# ruff: noqa: E501 Line too long

import typing
from typing import TYPE_CHECKING, Annotated, Any, Optional, Sequence, Callable, List

import platformics.database.models as base_db
from platformics.graphql_api.core.strawberry_helpers import get_aggregate_selections, get_nested_selected_fields
import database.models as db
import strawberry
import datetime
from platformics.graphql_api.core.query_builder import get_db_rows, get_aggregate_db_rows
from validators.run import RunCreateInputValidator
from validators.run import RunUpdateInputValidator
from graphql_api.helpers.run import RunGroupByOptions, build_run_groupby_output
from platformics.graphql_api.core.relay_interface import EntityInterface
from graphql_api.types.alignment import AlignmentAggregate, format_alignment_aggregate_output
from graphql_api.types.annotation import AnnotationAggregate, format_annotation_aggregate_output
from graphql_api.types.frame import FrameAggregate, format_frame_aggregate_output
from graphql_api.types.gain_file import GainFileAggregate, format_gain_file_aggregate_output
from graphql_api.types.frame_acquisition_file import (
    FrameAcquisitionFileAggregate,
    format_frame_acquisition_file_aggregate_output,
)
from graphql_api.types.per_section_parameters import (
    PerSectionParametersAggregate,
    format_per_section_parameters_aggregate_output,
)
from graphql_api.types.tiltseries import TiltseriesAggregate, format_tiltseries_aggregate_output
from graphql_api.types.tomogram_voxel_spacing import (
    TomogramVoxelSpacingAggregate,
    format_tomogram_voxel_spacing_aggregate_output,
)
from graphql_api.types.tomogram import TomogramAggregate, format_tomogram_aggregate_output
from fastapi import Depends
from platformics.graphql_api.core.errors import PlatformicsError
from platformics.graphql_api.core.deps import get_authz_client, get_db_session, require_auth_principal, is_system_user
from platformics.graphql_api.core.query_input_types import (
    aggregator_map,
    orderBy,
    EnumComparators,
    DatetimeComparators,
    IntComparators,
    FloatComparators,
    StrComparators,
    UUIDComparators,
    BoolComparators,
)
from platformics.graphql_api.core.strawberry_extensions import DependencyExtension
from platformics.security.authorization import AuthzAction, AuthzClient, Principal
from sqlalchemy import inspect
from sqlalchemy.engine.row import RowMapping
from sqlalchemy.ext.asyncio import AsyncSession
from strawberry import relay
from strawberry.types import Info
from support.limit_offset import LimitOffsetClause
from typing_extensions import TypedDict
import enum

E = typing.TypeVar("E")
T = typing.TypeVar("T")

if TYPE_CHECKING:
    from graphql_api.types.alignment import (
        AlignmentOrderByClause,
        AlignmentAggregateWhereClause,
        AlignmentWhereClause,
        Alignment,
    )
    from graphql_api.types.annotation import (
        AnnotationOrderByClause,
        AnnotationAggregateWhereClause,
        AnnotationWhereClause,
        Annotation,
    )
    from graphql_api.types.dataset import DatasetOrderByClause, DatasetAggregateWhereClause, DatasetWhereClause, Dataset
    from graphql_api.types.frame import FrameOrderByClause, FrameAggregateWhereClause, FrameWhereClause, Frame
    from graphql_api.types.gain_file import (
        GainFileOrderByClause,
        GainFileAggregateWhereClause,
        GainFileWhereClause,
        GainFile,
    )
    from graphql_api.types.frame_acquisition_file import (
        FrameAcquisitionFileOrderByClause,
        FrameAcquisitionFileAggregateWhereClause,
        FrameAcquisitionFileWhereClause,
        FrameAcquisitionFile,
    )
    from graphql_api.types.per_section_parameters import (
        PerSectionParametersOrderByClause,
        PerSectionParametersAggregateWhereClause,
        PerSectionParametersWhereClause,
        PerSectionParameters,
    )
    from graphql_api.types.tiltseries import (
        TiltseriesOrderByClause,
        TiltseriesAggregateWhereClause,
        TiltseriesWhereClause,
        Tiltseries,
    )
    from graphql_api.types.tomogram_voxel_spacing import (
        TomogramVoxelSpacingOrderByClause,
        TomogramVoxelSpacingAggregateWhereClause,
        TomogramVoxelSpacingWhereClause,
        TomogramVoxelSpacing,
    )
    from graphql_api.types.tomogram import (
        TomogramOrderByClause,
        TomogramAggregateWhereClause,
        TomogramWhereClause,
        Tomogram,
    )

    pass
else:
    AlignmentWhereClause = "AlignmentWhereClause"
    AlignmentAggregateWhereClause = "AlignmentAggregateWhereClause"
    Alignment = "Alignment"
    AlignmentOrderByClause = "AlignmentOrderByClause"
    AnnotationWhereClause = "AnnotationWhereClause"
    AnnotationAggregateWhereClause = "AnnotationAggregateWhereClause"
    Annotation = "Annotation"
    AnnotationOrderByClause = "AnnotationOrderByClause"
    DatasetWhereClause = "DatasetWhereClause"
    DatasetAggregateWhereClause = "DatasetAggregateWhereClause"
    Dataset = "Dataset"
    DatasetOrderByClause = "DatasetOrderByClause"
    FrameWhereClause = "FrameWhereClause"
    FrameAggregateWhereClause = "FrameAggregateWhereClause"
    Frame = "Frame"
    FrameOrderByClause = "FrameOrderByClause"
    GainFileWhereClause = "GainFileWhereClause"
    GainFileAggregateWhereClause = "GainFileAggregateWhereClause"
    GainFile = "GainFile"
    GainFileOrderByClause = "GainFileOrderByClause"
    FrameAcquisitionFileWhereClause = "FrameAcquisitionFileWhereClause"
    FrameAcquisitionFileAggregateWhereClause = "FrameAcquisitionFileAggregateWhereClause"
    FrameAcquisitionFile = "FrameAcquisitionFile"
    FrameAcquisitionFileOrderByClause = "FrameAcquisitionFileOrderByClause"
    PerSectionParametersWhereClause = "PerSectionParametersWhereClause"
    PerSectionParametersAggregateWhereClause = "PerSectionParametersAggregateWhereClause"
    PerSectionParameters = "PerSectionParameters"
    PerSectionParametersOrderByClause = "PerSectionParametersOrderByClause"
    TiltseriesWhereClause = "TiltseriesWhereClause"
    TiltseriesAggregateWhereClause = "TiltseriesAggregateWhereClause"
    Tiltseries = "Tiltseries"
    TiltseriesOrderByClause = "TiltseriesOrderByClause"
    TomogramVoxelSpacingWhereClause = "TomogramVoxelSpacingWhereClause"
    TomogramVoxelSpacingAggregateWhereClause = "TomogramVoxelSpacingAggregateWhereClause"
    TomogramVoxelSpacing = "TomogramVoxelSpacing"
    TomogramVoxelSpacingOrderByClause = "TomogramVoxelSpacingOrderByClause"
    TomogramWhereClause = "TomogramWhereClause"
    TomogramAggregateWhereClause = "TomogramAggregateWhereClause"
    Tomogram = "Tomogram"
    TomogramOrderByClause = "TomogramOrderByClause"
    pass


"""
------------------------------------------------------------------------------
Dataloaders
------------------------------------------------------------------------------
These are batching functions for loading related objects to avoid N+1 queries.
"""


@relay.connection(
    relay.ListConnection[Annotated["Alignment", strawberry.lazy("graphql_api.types.alignment")]]  # type:ignore
)
async def load_alignment_rows(
    root: "Run",
    info: Info,
    where: Annotated["AlignmentWhereClause", strawberry.lazy("graphql_api.types.alignment")] | None = None,
    order_by: Optional[list[Annotated["AlignmentOrderByClause", strawberry.lazy("graphql_api.types.alignment")]]] = [],
) -> Sequence[Annotated["Alignment", strawberry.lazy("graphql_api.types.alignment")]]:
    dataloader = info.context["sqlalchemy_loader"]
    mapper = inspect(db.Run)
    relationship = mapper.relationships["alignments"]
    return await dataloader.loader_for(relationship, where, order_by).load(root.id)  # type:ignore


@strawberry.field
async def load_alignment_aggregate_rows(
    root: "Run",
    info: Info,
    where: Annotated["AlignmentWhereClause", strawberry.lazy("graphql_api.types.alignment")] | None = None,
) -> Optional[Annotated["AlignmentAggregate", strawberry.lazy("graphql_api.types.alignment")]]:
    selections = get_nested_selected_fields(info.selected_fields)
    dataloader = info.context["sqlalchemy_loader"]
    mapper = inspect(db.Run)
    relationship = mapper.relationships["alignments"]
    rows = await dataloader.aggregate_loader_for(relationship, where, selections).load(root.id)  # type:ignore
    aggregate_output = format_alignment_aggregate_output(rows)
    return aggregate_output


@relay.connection(
    relay.ListConnection[Annotated["Annotation", strawberry.lazy("graphql_api.types.annotation")]]  # type:ignore
)
async def load_annotation_rows(
    root: "Run",
    info: Info,
    where: Annotated["AnnotationWhereClause", strawberry.lazy("graphql_api.types.annotation")] | None = None,
    order_by: Optional[
        list[Annotated["AnnotationOrderByClause", strawberry.lazy("graphql_api.types.annotation")]]
    ] = [],
) -> Sequence[Annotated["Annotation", strawberry.lazy("graphql_api.types.annotation")]]:
    dataloader = info.context["sqlalchemy_loader"]
    mapper = inspect(db.Run)
    relationship = mapper.relationships["annotations"]
    return await dataloader.loader_for(relationship, where, order_by).load(root.id)  # type:ignore


@strawberry.field
async def load_annotation_aggregate_rows(
    root: "Run",
    info: Info,
    where: Annotated["AnnotationWhereClause", strawberry.lazy("graphql_api.types.annotation")] | None = None,
) -> Optional[Annotated["AnnotationAggregate", strawberry.lazy("graphql_api.types.annotation")]]:
    selections = get_nested_selected_fields(info.selected_fields)
    dataloader = info.context["sqlalchemy_loader"]
    mapper = inspect(db.Run)
    relationship = mapper.relationships["annotations"]
    rows = await dataloader.aggregate_loader_for(relationship, where, selections).load(root.id)  # type:ignore
    aggregate_output = format_annotation_aggregate_output(rows)
    return aggregate_output


@strawberry.field
async def load_dataset_rows(
    root: "Run",
    info: Info,
    where: Annotated["DatasetWhereClause", strawberry.lazy("graphql_api.types.dataset")] | None = None,
    order_by: Optional[list[Annotated["DatasetOrderByClause", strawberry.lazy("graphql_api.types.dataset")]]] = [],
) -> Optional[Annotated["Dataset", strawberry.lazy("graphql_api.types.dataset")]]:
    dataloader = info.context["sqlalchemy_loader"]
    mapper = inspect(db.Run)
    relationship = mapper.relationships["dataset"]
    return await dataloader.loader_for(relationship, where, order_by).load(root.dataset_id)  # type:ignore


@relay.connection(
    relay.ListConnection[Annotated["Frame", strawberry.lazy("graphql_api.types.frame")]]  # type:ignore
)
async def load_frame_rows(
    root: "Run",
    info: Info,
    where: Annotated["FrameWhereClause", strawberry.lazy("graphql_api.types.frame")] | None = None,
    order_by: Optional[list[Annotated["FrameOrderByClause", strawberry.lazy("graphql_api.types.frame")]]] = [],
) -> Sequence[Annotated["Frame", strawberry.lazy("graphql_api.types.frame")]]:
    dataloader = info.context["sqlalchemy_loader"]
    mapper = inspect(db.Run)
    relationship = mapper.relationships["frames"]
    return await dataloader.loader_for(relationship, where, order_by).load(root.id)  # type:ignore


@strawberry.field
async def load_frame_aggregate_rows(
    root: "Run",
    info: Info,
    where: Annotated["FrameWhereClause", strawberry.lazy("graphql_api.types.frame")] | None = None,
) -> Optional[Annotated["FrameAggregate", strawberry.lazy("graphql_api.types.frame")]]:
    selections = get_nested_selected_fields(info.selected_fields)
    dataloader = info.context["sqlalchemy_loader"]
    mapper = inspect(db.Run)
    relationship = mapper.relationships["frames"]
    rows = await dataloader.aggregate_loader_for(relationship, where, selections).load(root.id)  # type:ignore
    aggregate_output = format_frame_aggregate_output(rows)
    return aggregate_output


@relay.connection(
    relay.ListConnection[Annotated["GainFile", strawberry.lazy("graphql_api.types.gain_file")]]  # type:ignore
)
async def load_gain_file_rows(
    root: "Run",
    info: Info,
    where: Annotated["GainFileWhereClause", strawberry.lazy("graphql_api.types.gain_file")] | None = None,
    order_by: Optional[list[Annotated["GainFileOrderByClause", strawberry.lazy("graphql_api.types.gain_file")]]] = [],
) -> Sequence[Annotated["GainFile", strawberry.lazy("graphql_api.types.gain_file")]]:
    dataloader = info.context["sqlalchemy_loader"]
    mapper = inspect(db.Run)
    relationship = mapper.relationships["gain_files"]
    return await dataloader.loader_for(relationship, where, order_by).load(root.id)  # type:ignore


@strawberry.field
async def load_gain_file_aggregate_rows(
    root: "Run",
    info: Info,
    where: Annotated["GainFileWhereClause", strawberry.lazy("graphql_api.types.gain_file")] | None = None,
) -> Optional[Annotated["GainFileAggregate", strawberry.lazy("graphql_api.types.gain_file")]]:
    selections = get_nested_selected_fields(info.selected_fields)
    dataloader = info.context["sqlalchemy_loader"]
    mapper = inspect(db.Run)
    relationship = mapper.relationships["gain_files"]
    rows = await dataloader.aggregate_loader_for(relationship, where, selections).load(root.id)  # type:ignore
    aggregate_output = format_gain_file_aggregate_output(rows)
    return aggregate_output


@relay.connection(
    relay.ListConnection[Annotated["FrameAcquisitionFile", strawberry.lazy("graphql_api.types.frame_acquisition_file")]]  # type:ignore
)
async def load_frame_acquisition_file_rows(
    root: "Run",
    info: Info,
    where: (
        Annotated["FrameAcquisitionFileWhereClause", strawberry.lazy("graphql_api.types.frame_acquisition_file")] | None
    ) = None,
    order_by: Optional[
        list[
            Annotated["FrameAcquisitionFileOrderByClause", strawberry.lazy("graphql_api.types.frame_acquisition_file")]
        ]
    ] = [],
) -> Sequence[Annotated["FrameAcquisitionFile", strawberry.lazy("graphql_api.types.frame_acquisition_file")]]:
    dataloader = info.context["sqlalchemy_loader"]
    mapper = inspect(db.Run)
    relationship = mapper.relationships["frame_acquisition_files"]
    return await dataloader.loader_for(relationship, where, order_by).load(root.id)  # type:ignore


@strawberry.field
async def load_frame_acquisition_file_aggregate_rows(
    root: "Run",
    info: Info,
    where: (
        Annotated["FrameAcquisitionFileWhereClause", strawberry.lazy("graphql_api.types.frame_acquisition_file")] | None
    ) = None,
) -> Optional[Annotated["FrameAcquisitionFileAggregate", strawberry.lazy("graphql_api.types.frame_acquisition_file")]]:
    selections = get_nested_selected_fields(info.selected_fields)
    dataloader = info.context["sqlalchemy_loader"]
    mapper = inspect(db.Run)
    relationship = mapper.relationships["frame_acquisition_files"]
    rows = await dataloader.aggregate_loader_for(relationship, where, selections).load(root.id)  # type:ignore
    aggregate_output = format_frame_acquisition_file_aggregate_output(rows)
    return aggregate_output


@relay.connection(
    relay.ListConnection[Annotated["PerSectionParameters", strawberry.lazy("graphql_api.types.per_section_parameters")]]  # type:ignore
)
async def load_per_section_parameters_rows(
    root: "Run",
    info: Info,
    where: (
        Annotated["PerSectionParametersWhereClause", strawberry.lazy("graphql_api.types.per_section_parameters")] | None
    ) = None,
    order_by: Optional[
        list[
            Annotated["PerSectionParametersOrderByClause", strawberry.lazy("graphql_api.types.per_section_parameters")]
        ]
    ] = [],
) -> Sequence[Annotated["PerSectionParameters", strawberry.lazy("graphql_api.types.per_section_parameters")]]:
    dataloader = info.context["sqlalchemy_loader"]
    mapper = inspect(db.Run)
    relationship = mapper.relationships["per_section_parameters"]
    return await dataloader.loader_for(relationship, where, order_by).load(root.id)  # type:ignore


@strawberry.field
async def load_per_section_parameters_aggregate_rows(
    root: "Run",
    info: Info,
    where: (
        Annotated["PerSectionParametersWhereClause", strawberry.lazy("graphql_api.types.per_section_parameters")] | None
    ) = None,
) -> Optional[Annotated["PerSectionParametersAggregate", strawberry.lazy("graphql_api.types.per_section_parameters")]]:
    selections = get_nested_selected_fields(info.selected_fields)
    dataloader = info.context["sqlalchemy_loader"]
    mapper = inspect(db.Run)
    relationship = mapper.relationships["per_section_parameters"]
    rows = await dataloader.aggregate_loader_for(relationship, where, selections).load(root.id)  # type:ignore
    aggregate_output = format_per_section_parameters_aggregate_output(rows)
    return aggregate_output


@relay.connection(
    relay.ListConnection[Annotated["Tiltseries", strawberry.lazy("graphql_api.types.tiltseries")]]  # type:ignore
)
async def load_tiltseries_rows(
    root: "Run",
    info: Info,
    where: Annotated["TiltseriesWhereClause", strawberry.lazy("graphql_api.types.tiltseries")] | None = None,
    order_by: Optional[
        list[Annotated["TiltseriesOrderByClause", strawberry.lazy("graphql_api.types.tiltseries")]]
    ] = [],
) -> Sequence[Annotated["Tiltseries", strawberry.lazy("graphql_api.types.tiltseries")]]:
    dataloader = info.context["sqlalchemy_loader"]
    mapper = inspect(db.Run)
    relationship = mapper.relationships["tiltseries"]
    return await dataloader.loader_for(relationship, where, order_by).load(root.id)  # type:ignore


@strawberry.field
async def load_tiltseries_aggregate_rows(
    root: "Run",
    info: Info,
    where: Annotated["TiltseriesWhereClause", strawberry.lazy("graphql_api.types.tiltseries")] | None = None,
) -> Optional[Annotated["TiltseriesAggregate", strawberry.lazy("graphql_api.types.tiltseries")]]:
    selections = get_nested_selected_fields(info.selected_fields)
    dataloader = info.context["sqlalchemy_loader"]
    mapper = inspect(db.Run)
    relationship = mapper.relationships["tiltseries"]
    rows = await dataloader.aggregate_loader_for(relationship, where, selections).load(root.id)  # type:ignore
    aggregate_output = format_tiltseries_aggregate_output(rows)
    return aggregate_output


@relay.connection(
    relay.ListConnection[Annotated["TomogramVoxelSpacing", strawberry.lazy("graphql_api.types.tomogram_voxel_spacing")]]  # type:ignore
)
async def load_tomogram_voxel_spacing_rows(
    root: "Run",
    info: Info,
    where: (
        Annotated["TomogramVoxelSpacingWhereClause", strawberry.lazy("graphql_api.types.tomogram_voxel_spacing")] | None
    ) = None,
    order_by: Optional[
        list[
            Annotated["TomogramVoxelSpacingOrderByClause", strawberry.lazy("graphql_api.types.tomogram_voxel_spacing")]
        ]
    ] = [],
) -> Sequence[Annotated["TomogramVoxelSpacing", strawberry.lazy("graphql_api.types.tomogram_voxel_spacing")]]:
    dataloader = info.context["sqlalchemy_loader"]
    mapper = inspect(db.Run)
    relationship = mapper.relationships["tomogram_voxel_spacings"]
    return await dataloader.loader_for(relationship, where, order_by).load(root.id)  # type:ignore


@strawberry.field
async def load_tomogram_voxel_spacing_aggregate_rows(
    root: "Run",
    info: Info,
    where: (
        Annotated["TomogramVoxelSpacingWhereClause", strawberry.lazy("graphql_api.types.tomogram_voxel_spacing")] | None
    ) = None,
) -> Optional[Annotated["TomogramVoxelSpacingAggregate", strawberry.lazy("graphql_api.types.tomogram_voxel_spacing")]]:
    selections = get_nested_selected_fields(info.selected_fields)
    dataloader = info.context["sqlalchemy_loader"]
    mapper = inspect(db.Run)
    relationship = mapper.relationships["tomogram_voxel_spacings"]
    rows = await dataloader.aggregate_loader_for(relationship, where, selections).load(root.id)  # type:ignore
    aggregate_output = format_tomogram_voxel_spacing_aggregate_output(rows)
    return aggregate_output


@relay.connection(
    relay.ListConnection[Annotated["Tomogram", strawberry.lazy("graphql_api.types.tomogram")]]  # type:ignore
)
async def load_tomogram_rows(
    root: "Run",
    info: Info,
    where: Annotated["TomogramWhereClause", strawberry.lazy("graphql_api.types.tomogram")] | None = None,
    order_by: Optional[list[Annotated["TomogramOrderByClause", strawberry.lazy("graphql_api.types.tomogram")]]] = [],
) -> Sequence[Annotated["Tomogram", strawberry.lazy("graphql_api.types.tomogram")]]:
    dataloader = info.context["sqlalchemy_loader"]
    mapper = inspect(db.Run)
    relationship = mapper.relationships["tomograms"]
    return await dataloader.loader_for(relationship, where, order_by).load(root.id)  # type:ignore


@strawberry.field
async def load_tomogram_aggregate_rows(
    root: "Run",
    info: Info,
    where: Annotated["TomogramWhereClause", strawberry.lazy("graphql_api.types.tomogram")] | None = None,
) -> Optional[Annotated["TomogramAggregate", strawberry.lazy("graphql_api.types.tomogram")]]:
    selections = get_nested_selected_fields(info.selected_fields)
    dataloader = info.context["sqlalchemy_loader"]
    mapper = inspect(db.Run)
    relationship = mapper.relationships["tomograms"]
    rows = await dataloader.aggregate_loader_for(relationship, where, selections).load(root.id)  # type:ignore
    aggregate_output = format_tomogram_aggregate_output(rows)
    return aggregate_output


"""
------------------------------------------------------------------------------
Define Strawberry GQL types
------------------------------------------------------------------------------
"""


"""
Only let users specify IDs in WHERE clause when mutating data (for safety).
We can extend that list as we gather more use cases from the FE team.
"""


@strawberry.input
class RunWhereClauseMutations(TypedDict):
    id: IntComparators | None


"""
Supported WHERE clause attributes
"""


@strawberry.input
class RunWhereClause(TypedDict):
    alignments: Optional[Annotated["AlignmentWhereClause", strawberry.lazy("graphql_api.types.alignment")]] | None
    alignments_aggregate: (
        Optional[Annotated["AlignmentAggregateWhereClause", strawberry.lazy("graphql_api.types.alignment")]] | None
    )
    annotations: Optional[Annotated["AnnotationWhereClause", strawberry.lazy("graphql_api.types.annotation")]] | None
    annotations_aggregate: (
        Optional[Annotated["AnnotationAggregateWhereClause", strawberry.lazy("graphql_api.types.annotation")]] | None
    )
    dataset: Optional[Annotated["DatasetWhereClause", strawberry.lazy("graphql_api.types.dataset")]] | None
    dataset_id: Optional[IntComparators] | None
    frames: Optional[Annotated["FrameWhereClause", strawberry.lazy("graphql_api.types.frame")]] | None
    frames_aggregate: (
        Optional[Annotated["FrameAggregateWhereClause", strawberry.lazy("graphql_api.types.frame")]] | None
    )
    gain_files: Optional[Annotated["GainFileWhereClause", strawberry.lazy("graphql_api.types.gain_file")]] | None
    gain_files_aggregate: (
        Optional[Annotated["GainFileAggregateWhereClause", strawberry.lazy("graphql_api.types.gain_file")]] | None
    )
    frame_acquisition_files: (
        Optional[
            Annotated["FrameAcquisitionFileWhereClause", strawberry.lazy("graphql_api.types.frame_acquisition_file")]
        ]
        | None
    )
    frame_acquisition_files_aggregate: (
        Optional[
            Annotated[
                "FrameAcquisitionFileAggregateWhereClause", strawberry.lazy("graphql_api.types.frame_acquisition_file")
            ]
        ]
        | None
    )
    per_section_parameters: (
        Optional[
            Annotated["PerSectionParametersWhereClause", strawberry.lazy("graphql_api.types.per_section_parameters")]
        ]
        | None
    )
    per_section_parameters_aggregate: (
        Optional[
            Annotated[
                "PerSectionParametersAggregateWhereClause", strawberry.lazy("graphql_api.types.per_section_parameters")
            ]
        ]
        | None
    )
    tiltseries: Optional[Annotated["TiltseriesWhereClause", strawberry.lazy("graphql_api.types.tiltseries")]] | None
    tiltseries_aggregate: (
        Optional[Annotated["TiltseriesAggregateWhereClause", strawberry.lazy("graphql_api.types.tiltseries")]] | None
    )
    tomogram_voxel_spacings: (
        Optional[
            Annotated["TomogramVoxelSpacingWhereClause", strawberry.lazy("graphql_api.types.tomogram_voxel_spacing")]
        ]
        | None
    )
    tomogram_voxel_spacings_aggregate: (
        Optional[
            Annotated[
                "TomogramVoxelSpacingAggregateWhereClause", strawberry.lazy("graphql_api.types.tomogram_voxel_spacing")
            ]
        ]
        | None
    )
    tomograms: Optional[Annotated["TomogramWhereClause", strawberry.lazy("graphql_api.types.tomogram")]] | None
    tomograms_aggregate: (
        Optional[Annotated["TomogramAggregateWhereClause", strawberry.lazy("graphql_api.types.tomogram")]] | None
    )
    name: Optional[StrComparators] | None
    s3_prefix: Optional[StrComparators] | None
    https_prefix: Optional[StrComparators] | None
    id: Optional[IntComparators] | None


"""
Supported ORDER BY clause attributes
"""


@strawberry.input
class RunOrderByClause(TypedDict):
    dataset: Optional[Annotated["DatasetOrderByClause", strawberry.lazy("graphql_api.types.dataset")]] | None
    name: Optional[orderBy] | None
    s3_prefix: Optional[orderBy] | None
    https_prefix: Optional[orderBy] | None
    id: Optional[orderBy] | None


"""
Define Run type
"""


@strawberry.type(description=None)
class Run(EntityInterface):
    alignments: Sequence[Annotated["Alignment", strawberry.lazy("graphql_api.types.alignment")]] = load_alignment_rows  # type:ignore
    alignments_aggregate: Optional[Annotated["AlignmentAggregate", strawberry.lazy("graphql_api.types.alignment")]] = (
        load_alignment_aggregate_rows  # type:ignore
    )
    annotations: Sequence[Annotated["Annotation", strawberry.lazy("graphql_api.types.annotation")]] = (
        load_annotation_rows  # type:ignore
    )
    annotations_aggregate: Optional[
        Annotated["AnnotationAggregate", strawberry.lazy("graphql_api.types.annotation")]
    ] = load_annotation_aggregate_rows  # type:ignore
    dataset: Optional[Annotated["Dataset", strawberry.lazy("graphql_api.types.dataset")]] = load_dataset_rows  # type:ignore
    dataset_id: int
    frames: Sequence[Annotated["Frame", strawberry.lazy("graphql_api.types.frame")]] = load_frame_rows  # type:ignore
    frames_aggregate: Optional[Annotated["FrameAggregate", strawberry.lazy("graphql_api.types.frame")]] = (
        load_frame_aggregate_rows  # type:ignore
    )
    gain_files: Sequence[Annotated["GainFile", strawberry.lazy("graphql_api.types.gain_file")]] = load_gain_file_rows  # type:ignore
    gain_files_aggregate: Optional[Annotated["GainFileAggregate", strawberry.lazy("graphql_api.types.gain_file")]] = (
        load_gain_file_aggregate_rows  # type:ignore
    )
    frame_acquisition_files: Sequence[
        Annotated["FrameAcquisitionFile", strawberry.lazy("graphql_api.types.frame_acquisition_file")]
    ] = load_frame_acquisition_file_rows  # type:ignore
    frame_acquisition_files_aggregate: Optional[
        Annotated["FrameAcquisitionFileAggregate", strawberry.lazy("graphql_api.types.frame_acquisition_file")]
    ] = load_frame_acquisition_file_aggregate_rows  # type:ignore
    per_section_parameters: Sequence[
        Annotated["PerSectionParameters", strawberry.lazy("graphql_api.types.per_section_parameters")]
    ] = load_per_section_parameters_rows  # type:ignore
    per_section_parameters_aggregate: Optional[
        Annotated["PerSectionParametersAggregate", strawberry.lazy("graphql_api.types.per_section_parameters")]
    ] = load_per_section_parameters_aggregate_rows  # type:ignore
    tiltseries: Sequence[Annotated["Tiltseries", strawberry.lazy("graphql_api.types.tiltseries")]] = (
        load_tiltseries_rows  # type:ignore
    )
    tiltseries_aggregate: Optional[
        Annotated["TiltseriesAggregate", strawberry.lazy("graphql_api.types.tiltseries")]
    ] = load_tiltseries_aggregate_rows  # type:ignore
    tomogram_voxel_spacings: Sequence[
        Annotated["TomogramVoxelSpacing", strawberry.lazy("graphql_api.types.tomogram_voxel_spacing")]
    ] = load_tomogram_voxel_spacing_rows  # type:ignore
    tomogram_voxel_spacings_aggregate: Optional[
        Annotated["TomogramVoxelSpacingAggregate", strawberry.lazy("graphql_api.types.tomogram_voxel_spacing")]
    ] = load_tomogram_voxel_spacing_aggregate_rows  # type:ignore
    tomograms: Sequence[Annotated["Tomogram", strawberry.lazy("graphql_api.types.tomogram")]] = load_tomogram_rows  # type:ignore
    tomograms_aggregate: Optional[Annotated["TomogramAggregate", strawberry.lazy("graphql_api.types.tomogram")]] = (
        load_tomogram_aggregate_rows  # type:ignore
    )
    name: str = strawberry.field(description="Short name for this experiment run")
    s3_prefix: str = strawberry.field(description="The S3 public bucket path where this run is contained")
    https_prefix: str = strawberry.field(description="The HTTPS directory path where this run is contained url")
    id: int = strawberry.field(description="Numeric identifier (May change!)")


"""
We need to add this to each Queryable type so that strawberry will accept either our
Strawberry type *or* a SQLAlchemy model instance as a valid response class from a resolver
"""
Run.__strawberry_definition__.is_type_of = lambda obj, info: type(obj) == db.Run or type(obj) == Run  # type: ignore

"""
------------------------------------------------------------------------------
Aggregation types
------------------------------------------------------------------------------
"""
"""
Define columns that support numerical aggregations
"""


@strawberry.type
class RunNumericalColumns:
    id: Optional[int] = None


"""
Define columns that support min/max aggregations
"""


@strawberry.type
class RunMinMaxColumns:
    name: Optional[str] = None
    s3_prefix: Optional[str] = None
    https_prefix: Optional[str] = None
    id: Optional[int] = None


"""
Define enum of all columns to support count and count(distinct) aggregations
"""


@strawberry.enum
class RunCountColumns(enum.Enum):
    name = "name"
    s3Prefix = "s3_prefix"
    httpsPrefix = "https_prefix"
    id = "id"


"""
Support *filtering* on aggregates and related aggregates
"""


@strawberry.input
class RunAggregateWhereClauseCount(TypedDict):
    arguments: Optional["RunCountColumns"] | None
    distinct: Optional[bool] | None
    filter: Optional[RunWhereClause] | None
    predicate: Optional[IntComparators] | None


@strawberry.input
class RunAggregateWhereClause(TypedDict):
    count: RunAggregateWhereClauseCount


"""
All supported aggregation functions
"""


@strawberry.type
class RunAggregateFunctions:
    # This is a hack to accept "distinct" and "columns" as arguments to "count"
    @strawberry.field
    def count(self, distinct: Optional[bool] = False, columns: Optional[RunCountColumns] = None) -> Optional[int]:
        # Count gets set with the proper value in the resolver, so we just return it here
        return self.count  # type: ignore

    sum: Optional[RunNumericalColumns] = None
    avg: Optional[RunNumericalColumns] = None
    stddev: Optional[RunNumericalColumns] = None
    variance: Optional[RunNumericalColumns] = None
    min: Optional[RunMinMaxColumns] = None
    max: Optional[RunMinMaxColumns] = None
    groupBy: Optional[RunGroupByOptions] = None


"""
Wrapper around RunAggregateFunctions
"""


@strawberry.type
class RunAggregate:
    aggregate: Optional[list[RunAggregateFunctions]] = None


"""
------------------------------------------------------------------------------
Mutation types
------------------------------------------------------------------------------
"""


@strawberry.input()
class RunCreateInput:
    dataset_id: strawberry.ID = strawberry.field(description="Dataset that this run is a part of")
    name: str = strawberry.field(description="Short name for this experiment run")
    s3_prefix: str = strawberry.field(description="The S3 public bucket path where this run is contained")
    https_prefix: str = strawberry.field(description="The HTTPS directory path where this run is contained url")
    id: int = strawberry.field(description="Numeric identifier (May change!)")


@strawberry.input()
class RunUpdateInput:
    dataset_id: Optional[strawberry.ID] = strawberry.field(description="Dataset that this run is a part of")
    name: Optional[str] = strawberry.field(description="Short name for this experiment run")
    s3_prefix: Optional[str] = strawberry.field(description="The S3 public bucket path where this run is contained")
    https_prefix: Optional[str] = strawberry.field(
        description="The HTTPS directory path where this run is contained url"
    )
    id: Optional[int] = strawberry.field(description="Numeric identifier (May change!)")


"""
------------------------------------------------------------------------------
Utilities
------------------------------------------------------------------------------
"""


@strawberry.field(extensions=[DependencyExtension()])
async def resolve_runs(
    session: AsyncSession = Depends(get_db_session, use_cache=False),
    authz_client: AuthzClient = Depends(get_authz_client),
    principal: Principal = Depends(require_auth_principal),
    where: Optional[RunWhereClause] = None,
    order_by: Optional[list[RunOrderByClause]] = [],
    limit_offset: Optional[LimitOffsetClause] = None,
) -> typing.Sequence[Run]:
    """
    Resolve Run objects. Used for queries (see graphql_api/queries.py).
    """
    limit = limit_offset["limit"] if limit_offset and "limit" in limit_offset else None
    offset = limit_offset["offset"] if limit_offset and "offset" in limit_offset else None
    if offset and not limit:
        raise PlatformicsError("Cannot use offset without limit")
    return await get_db_rows(db.Run, session, authz_client, principal, where, order_by, AuthzAction.VIEW, limit, offset)  # type: ignore


def format_run_aggregate_output(query_results: Sequence[RowMapping] | RowMapping) -> RunAggregate:
    """
    Given a row from the DB containing the results of an aggregate query,
    format the results using the proper GraphQL types.
    """
    aggregate = []
    if not type(query_results) is list:
        query_results = [query_results]  # type: ignore
    for row in query_results:
        aggregate.append(format_run_aggregate_row(row))
    return RunAggregate(aggregate=aggregate)


def format_run_aggregate_row(row: RowMapping) -> RunAggregateFunctions:
    """
    Given a single row from the DB containing the results of an aggregate query,
    format the results using the proper GraphQL types.
    """
    output = RunAggregateFunctions()
    for key, value in row.items():
        # Key is either an aggregate function or a groupby key
        group_keys = key.split(".")
        aggregate = key.split("_", 1)
        if aggregate[0] not in aggregator_map.keys():
            # Turn list of groupby keys into nested objects
            if not getattr(output, "groupBy"):
                setattr(output, "groupBy", RunGroupByOptions())
            group = build_run_groupby_output(getattr(output, "groupBy"), group_keys, value)
            setattr(output, "groupBy", group)
        else:
            aggregate_name = aggregate[0]
            if aggregate_name == "count":
                output.count = value
            else:
                aggregator_fn, col_name = aggregate[0], aggregate[1]
                if not getattr(output, aggregator_fn):
                    if aggregate_name in ["min", "max"]:
                        setattr(output, aggregator_fn, RunMinMaxColumns())
                    else:
                        setattr(output, aggregator_fn, RunNumericalColumns())
                setattr(getattr(output, aggregator_fn), col_name, value)
    return output


@strawberry.field(extensions=[DependencyExtension()])
async def resolve_runs_aggregate(
    info: Info,
    session: AsyncSession = Depends(get_db_session, use_cache=False),
    authz_client: AuthzClient = Depends(get_authz_client),
    principal: Principal = Depends(require_auth_principal),
    where: Optional[RunWhereClause] = None,
    # TODO: add support for groupby, limit/offset
) -> RunAggregate:
    """
    Aggregate values for Run objects. Used for queries (see graphql_api/queries.py).
    """
    # Get the selected aggregate functions and columns to operate on, and groupby options if any were provided.
    # TODO: not sure why selected_fields is a list
    aggregate_selections, groupby_selections = get_aggregate_selections(info.selected_fields)

    if not aggregate_selections:
        raise PlatformicsError("No aggregate functions selected")

    rows = await get_aggregate_db_rows(
        db.Run, session, authz_client, principal, where, aggregate_selections, [], groupby_selections
    )  # type: ignore
    aggregate_output = format_run_aggregate_output(rows)
    return aggregate_output


@strawberry.mutation(extensions=[DependencyExtension()])
async def create_run(
    input: RunCreateInput,
    session: AsyncSession = Depends(get_db_session, use_cache=False),
    authz_client: AuthzClient = Depends(get_authz_client),
    principal: Principal = Depends(require_auth_principal),
    is_system_user: bool = Depends(is_system_user),
) -> db.Run:
    """
    Create a new Run object. Used for mutations (see graphql_api/mutations.py).
    """
    validated = RunCreateInputValidator(**input.__dict__)
    params = validated.model_dump()

    # Validate that the user can read all of the entities they're linking to.

    # Validate that the user can read all of the entities they're linking to.
    # Check that dataset relationship is accessible.
    if validated.dataset_id:
        dataset = await get_db_rows(
            db.Dataset, session, authz_client, principal, {"id": {"_eq": validated.dataset_id}}, [], AuthzAction.VIEW
        )
        if not dataset:
            raise PlatformicsError("Unauthorized: dataset does not exist")

    # Save to DB
    params["owner_user_id"] = int(principal.id)
    new_entity = db.Run(**params)

    # Are we actually allowed to create this entity?
    if not authz_client.can_create(new_entity, principal):
        raise PlatformicsError("Unauthorized: Cannot create entity")

    session.add(new_entity)
    await session.commit()
    return new_entity


@strawberry.mutation(extensions=[DependencyExtension()])
async def update_run(
    input: RunUpdateInput,
    where: RunWhereClauseMutations,
    session: AsyncSession = Depends(get_db_session, use_cache=False),
    authz_client: AuthzClient = Depends(get_authz_client),
    principal: Principal = Depends(require_auth_principal),
    is_system_user: bool = Depends(is_system_user),
) -> Sequence[db.Run]:
    """
    Update Run objects. Used for mutations (see graphql_api/mutations.py).
    """
    validated = RunUpdateInputValidator(**input.__dict__)
    params = validated.model_dump()

    # Need at least one thing to update
    num_params = len([x for x in params if params[x] is not None])
    if num_params == 0:
        raise PlatformicsError("No fields to update")

    # Validate that the user can read all of the entities they're linking to.
    # Check that dataset relationship is accessible.
    if validated.dataset_id:
        dataset = await get_db_rows(
            db.Dataset, session, authz_client, principal, {"id": {"_eq": validated.dataset_id}}, [], AuthzAction.VIEW
        )
        if not dataset:
            raise PlatformicsError("Unauthorized: dataset does not exist")
        params["dataset"] = dataset[0]
        del params["dataset_id"]

    # Fetch entities for update, if we have access to them
    entities = await get_db_rows(db.Run, session, authz_client, principal, where, [], AuthzAction.UPDATE)
    if len(entities) == 0:
        raise PlatformicsError("Unauthorized: Cannot update entities")

    # Update DB
    updated_at = datetime.datetime.now()
    for entity in entities:
        entity.updated_at = updated_at
        for key in params:
            if params[key] is not None:
                setattr(entity, key, params[key])

    if not authz_client.can_update(entity, principal):
        raise PlatformicsError("Unauthorized: Cannot access new collection")

    await session.commit()
    return entities


@strawberry.mutation(extensions=[DependencyExtension()])
async def delete_run(
    where: RunWhereClauseMutations,
    session: AsyncSession = Depends(get_db_session, use_cache=False),
    authz_client: AuthzClient = Depends(get_authz_client),
    principal: Principal = Depends(require_auth_principal),
) -> Sequence[db.Run]:
    """
    Delete Run objects. Used for mutations (see graphql_api/mutations.py).
    """
    # Fetch entities for deletion, if we have access to them
    entities = await get_db_rows(db.Run, session, authz_client, principal, where, [], AuthzAction.DELETE)
    if len(entities) == 0:
        raise PlatformicsError("Unauthorized: Cannot delete entities")

    # Update DB
    for entity in entities:
        await session.delete(entity)
    await session.commit()
    return entities
