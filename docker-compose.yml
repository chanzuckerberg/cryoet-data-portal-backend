services:
  nginx:
    image: nginx
    ports:
      - "4444:80"
    volumes:
      - ./test_infra/test_files:/usr/share/nginx/html
  motoserver:
    image: motoserver/moto:5.0.26
    ports:
      - "5566:5566"
    environment:
      - MOTO_PORT=5566
      - S3_IGNORE_SUBDOMAIN_BUCKETNAME=True
    volumes:
      - ./bin:/moto/bin
  db:
    image: postgres:14.2
    healthcheck:
      test: ["CMD", "pg_isready", "-d", "cryoet", "-U", "postgres"]
    environment:
      POSTGRES_INITDB_ARGS: --data-checksums
      POSTGRES_DB: cryoetv2
      POSTGRES_PASSWORD: postgres
      POSTGRES_USER: postgres
      # The postgres image declares a mounted volume at /var/lib/postgresql/data
      # by default, which means that the data in that directory is difficult to
      # snapshot and export. Here, we're telling Postgres to use this (non-mounted)
      # directory as its storage location instead so it works with our db snapshot
      # workflow.
      PGDATA: /var/lib/cryoetdataportal/data
    volumes:
      - ./test_infra:/test_infra
    ports:
      - "5432:5432"
  cerbos:
    image: ghcr.io/cerbos/cerbos:0.29.0
    profiles: ["api", "apiv2"]
    ports:
      - "3692:3692"
      - "3693:3693"
    volumes:
      - ./apiv2/cerbos:/var/policies/cerbos/
    command: ["server", "--config", "/var/policies/cerbos/config.yaml"]
  graphql-api:
    image: "graphql-api"
    profiles: ["api", "apiv2"]
    build:
      context: "apiv2"
      dockerfile: "Dockerfile"
      args:
        - BUILDKIT_INLINE_CACHE=1
    restart: always
    ports:
      - "9008:9008"
      - "9009:9009"
    environment:
      - PYTHONPATH=.
      - CERBOS_URL=http://cerbos:3692
      - PLATFORMICS_DATABASE_HOST=db
      - PLATFORMICS_DATABASE_PORT=5432
      - PLATFORMICS_DATABASE_USER=postgres
      - PLATFORMICS_DATABASE_PASSWORD=postgres
      - PLATFORMICS_DATABASE_NAME=cryoetv2
      - DEFAULT_UPLOAD_BUCKET=local-bucket
      - DEFAULT_UPLOAD_PROTOCOL=s3
      - OUTPUT_S3_PREFIX=platformics
      - BOTO_ENDPOINT_URL=http://motoserver:5566
      - AWS_REGION=us-west-2
      - AWS_ACCESS_KEY_ID=test
      - AWS_SECRET_ACCESS_KEY=test
      - DB_ECHO=true
      # TODO - these are keypairs for testing only! Do not use in prod!!
      - JWK_PUBLIC_KEY_FILE=/app/etc/public_key.pem
      - JWK_PRIVATE_KEY_FILE=/app/etc/private_key.pem
    volumes:
      - ./apiv2:/app
    command: ["/usr/local/bin/supervisord", "-c", "/app/etc/supervisord.conf"]
    depends_on:
      db:
        condition: service_healthy
